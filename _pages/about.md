---
permalink: /
title: "About me"
excerpt: "About me"
author_profile: true
redirect_from:
  - /about/
  - /about.html
---

<div style="text-align: justify"> 
Currently, I work as a Research Professor at the Korean Campus of Ghent University, mainly focusing on two areas: (1) image-based self-supervised learning, especially with vision transformers, and (2) explainable AI, frequently applied to biomedical imaging.

</div>

Here's a brief overview of my career, along with my current and past research focus:

------
  <span style="font-size:14px">*Current research focus:*</span>

  * <span style="font-size:12px">Biomedical imaging (<span style="color:maroon">B.img</span>) </span>
  * <span style="font-size:12px">Trustworthy and explainable AI (<span style="color:green">XAI</span>) </span>
  * <span style="font-size:12px">Image-based self-supervised learning (<span style="color:orange">SSL</span>)</span>

  <span style="font-size:14px">*Past research expertise:*</span>

  * <span style="font-size:12px">Bioinformatics (<span style="color:blue">B.inf</span>)</span>
  * <span style="font-size:12px">Adversarial examples: attacks, defenses, and properties (<span style="color:indigo">Adversarial</span>) </span>
  
------

2023 - Current: **Research Professor**, Ghent University Global Campus, South Korea

  <span style="font-size:14px">*Senior author Publications:*</span>
  * <span style="font-size:12px">(<span style="color:maroon">B.img</span>) Color Flow Imaging Microscopy Improves Identification of Stress Sources of Protein Aggregates in Biopharmaceuticals <br />*2024, MICCAI - MOVI Workshop*</span>
  * <span style="font-size:12px">(<span style="color:green">XAI</span>)-<span style="color:orange">SSL</span>) Visual Explanations of Attention Maps for Transformer-Based Medical Imaging <br />*2024, MICCAI - iMIMIC Workshop*</span>
  * <span style="font-size:12px">(<span style="color:green">XAI</span>)-<span style="color:orange">SSL</span>) Identifying Critical Tokens for Accurate Predictions in Transformer-based Medical Imaging Models <br />*2024, MICCAI - MLMI Workshop*</span>

  
  
  <span style="font-size:14px">*First author Publications:*</span>
  * <span style="font-size:12px">(<span style="color:orange">SSL</span>) Self-Supervised Benchmark Lottery on ImageNet: Do Marginal Improvements Translate to Improvements on Similar Datasets? <br />*2024, IEEE IJCNN*</span>
  * <span style="font-size:12px">(<span style="color:blue">B.inf</span>) Assessing the Reliability of Point Mutation as Data Augmentation for Deep Learning with Genomic Data<br />*2024, BMC Bioinformatics*</span>

  
2022 - 2023: **Postdoctoral Fellow**, Ghent University Global Campus, South Korea
  
  <span style="font-size:14px">*First author Publications:*</span>
  * <span style="font-size:12px">(<span style="color:orange">SSL</span>) Know Your Self-supervised Learning: A Survey on Image-based Generative and Discriminative Training<br />*2023, Transactions on Machine Learning Research*</span>
  * <span style="font-size:12px">(<span style="color:blue">B.inf</span>) BRCA Gene Mutations in dbSNP: A Visual Exploration of Genetic Variants<br />*2023, Arxiv*</span>
  * <span style="font-size:12px">(<span style="color:blue">B.inf</span>-<span style="color:green">XAI</span>) Mutate and Observe: Utilizing Deep Neural Networks to Investigate the Impact of Mutations on Translation Initiation<br />*2023, Bioinformatics, Oxford Press*</span>
  * <span style="font-size:12px">(<span style="color:blue">B.inf</span>-<span style="color:green">XAI</span>) Utilizing Mutations to Evaluate Interpretability of Neural Networks on Genomic Data<br />*2023, NeurIPS - LMRL Workshop*</span>
  
   <span style="font-size:14px">*Repositories*:</span>

  * <span style="font-size:12px">(<span style="color:blue">B.inf</span>) [github.com/utkuozbulak/mutate-and-observe](https://github.com/utkuozbulak/mutate-and-observe)</span>
 
------

2017 - 2022: **PhD in Computer Science**, Ghent University, Belgium
  
  <span style="font-size:14px">*First author Publications:*</span>
  * <span style="font-size:12px">(<span style="color:indigo">Adversarial</span>) Prevalence of Adversarial Examples in Neural Networks: Attacks, Defenses, and Opportunities<br />*2022, Ghent University, PhD thesis*</span>
  * <span style="font-size:12px">(<span style="color:indigo">Adversarial</span>-<span style="color:green">XAI</span>) Evaluating Adversarial Attacks on ImageNet: A Reality Check on Misclassification Classes<br />*2022, NeurIPS - Workshop on ImageNet: Past, Present, and Future*</span>
  * <span style="font-size:12px">(<span style="color:indigo">Adversarial</span>) Selection of Source Images Heavily Influences the Effectiveness of Adversarial Attacks<br />*2021, BMVC, oral presentation*</span>
  * <span style="font-size:12px">(<span style="color:indigo">Adversarial</span>-<span style="color:green">XAI</span>) Investigating the Significance of Adversarial Attacks and Their Relation to Interpretability for Radar-based Human Activity Recognition Systems<br />*2021, Computer Vision and Image Understanding, Elsevier*</span>
  * <span style="font-size:12px">(<span style="color:indigo">Adversarial</span>) Regional Image Perturbation Reduces Lp Norms of Adversarial Examples While Maintaining Model-to-model Transferability<br />*2020, ICML - UDL Workshop*</span>
  * <span style="font-size:12px">(<span style="color:indigo">Adversarial</span>) Perturbation Analysis of Gradient-based Adversarial Attacks<br />*2020, Pattern Recognition Letters, Elsevier*</span>
  * <span style="font-size:12px">(<span style="color:indigo">Adversarial</span>-<span style="color:maroon">B.img</span>) Impact of Adversarial Examples on Deep Learning Models for Biomedical Image Segmentation<br />*2019, MICCAI, poster presentation*</span>
  * <span style="font-size:12px">(<span style="color:indigo">Adversarial</span>) Not All Adversarial Examples Require a Complex Defense: Identifying Over-optimized Adversarial Examples with IQR-based Logit Thresholding<br />*2019, IEEE IJCNN, oral presentation* </span>
  * <span style="font-size:12px">(<span style="color:indigo">Adversarial</span>) How the Softmax Output is Misleading for Evaluating the Strength of Adversarial Examples<br />*2018, NeurIPS - SecML Workshop* </span>
  
  <span style="font-size:14px">*Repositories*:</span>
  * <span style="font-size:12px">(<span style="color:green">XAI</span>) [github.com/utkuozbulak/pytorch-cnn-visualizations](https://github.com/utkuozbulak/pytorch-cnn-visualizations)</span>
  * <span style="font-size:12px">(<span style="color:indigo">Adversarial</span>) [github.com/utkuozbulak/adaptive-segmentation-mask-attack](https://github.com/utkuozbulak/adaptive-segmentation-mask-attack)</span>
  * <span style="font-size:12px">(<span style="color:indigo">Adversarial</span>) [github.com/utkuozbulak/pytorch-cnn-adversarial-attacks](https://github.com/utkuozbulak/pytorch-cnn-adversarial-attacks)</span>
  * <span style="font-size:12px">(<span style="color:indigo">Adversarial</span>) [github.com/utkuozbulak/imagenet-adversarial-image-evaluation](https://github.com/utkuozbulak/imagenet-adversarial-image-evaluation)</span>
  * <span style="font-size:12px">(<span style="color:indigo">Adversarial</span>) [github.com/utkuozbulak/regional-adversarial-perturbation](https://github.com/utkuozbulak/regional-adversarial-perturbation)</span>
  * <span style="font-size:12px">(Other) [github.com/utkuozbulak/pytorch-custom-datasets](https://github.com/utkuozbulak/pytorch-custom-datasets)</span>


------

2016 - 2017: **MSc. in Data Science**, University of Southampton, UK

------

2014 - 2016: **SAP Business Intelligence Consultant**, Acron Consulting, Turkey

<span style="font-size:14px">*Notable clients:*</span>

  * <span style="font-size:12px">The Coca Cola Company</span>
  * <span style="font-size:12px">Turkish Airlines</span>
  * <span style="font-size:12px">Bosch Siemens Hausgerate</span>
  * <span style="font-size:12px">Flormar Cosmetics</span>

------

2012 - 2014: **BSc. in Computer Engineering**, Yasar University, Turkey



